{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import json\n",
    "import csv\n",
    "from PIL import Image, ImageDraw\n",
    "import cv2\n",
    "from matplotlib.pyplot import imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "SCALE_FACTOR = 2\n",
    "\n",
    "def draw_rectangle(I, xy):\n",
    "    img = Image.fromarray(I)\n",
    "    draw = ImageDraw.Draw(img)\n",
    "    draw.rectangle([xy[1], xy[0], xy[3], xy[2]])\n",
    "    text = str(np.round(xy[4], 2))\n",
    "    draw.text((xy[1], xy[0] - 10), text)\n",
    "    del draw\n",
    "    return img\n",
    "\n",
    "\n",
    "def downsample(I, factor):\n",
    "    assert(I.shape[0] % factor == 0 and I.shape[1] % factor == 0)\n",
    "    input_size = I.shape[:2]\n",
    "    output_size = [dim // factor for dim in I.shape[:2]]\n",
    "    small_image = I.reshape((output_size[0], factor, \n",
    "                             output_size[1], factor, 3)).max(3).max(1)\n",
    "    return small_image\n",
    "\n",
    "\n",
    "def calc_iou(A, B):\n",
    "    # Checks if bbox A and B intersect at all\n",
    "    # A fixed, B intersects top\n",
    "    summed_area = ((A[2] - A[0]) * (A[3] - A[1]) +\n",
    "                   (B[2] - B[0]) * (B[3] - B[1]))\n",
    "    i_area = 0\n",
    "    if A[1] >= B[1] and A[1] <= B[3]:\n",
    "        # intersects topleft\n",
    "        if A[0] >= B[0] and A[0] <= B[2]:\n",
    "            i_area = (B[2] - A[0]) * (B[3] - A[1])\n",
    "        # intersects topright\n",
    "        elif A[2] >= B[0] and A[2] <= B[2]:\n",
    "            i_area = (A[2] - B[0]) * (B[3] - A[1])\n",
    "    # B intersects bottom\n",
    "    elif A[3] >= B[1] and A[3] <= B[3]:\n",
    "        # intersects bottomleft\n",
    "        if A[0] >= B[0] and A[0] <= B[2]:\n",
    "            i_area = (B[2] - A[0]) * (A[3] - B[1])\n",
    "        # intersects bottomright\n",
    "        elif A[2] >= B[0] and A[2] <= B[2]:\n",
    "            i_area = (A[2] - B[0]) * (A[3] - B[1])\n",
    "    \n",
    "    return i_area / (summed_area - i_area)\n",
    "\n",
    "assert(calc_iou([0, 0, 10, 10], [5, 5, 15, 15]) == 25 / 175)\n",
    "\n",
    "\n",
    "def run_nms(bboxes, iou_thres=0.1):\n",
    "    # Assume bboxes' 4 coord is conf\n",
    "    valid_bboxes = []\n",
    "    bboxes = sorted(bboxes, key=lambda x:x[4], reverse=True)\n",
    "\n",
    "    for bbox in bboxes:\n",
    "        is_valid = True\n",
    "        for valid_bbox in valid_bboxes:\n",
    "            if calc_iou(bbox, valid_bbox) > iou_thres:\n",
    "                is_valid = False\n",
    "                break\n",
    "        if is_valid:\n",
    "            valid_bboxes.append(bbox)\n",
    "    return valid_bboxes\n",
    "\n",
    "\n",
    "def rgb_to_hsv(I):\n",
    "    '''\n",
    "    Turn a numpy RGB image to a numpy HSV image\n",
    "    '''\n",
    "    I = I / 255.0\n",
    "    cmax = np.max(I, axis=2)\n",
    "    cmin = np.min(I, axis=2)\n",
    "    diff = cmax - cmin\n",
    "    max_color = np.argmax(I, axis=2)\n",
    "    # initialize hsv\n",
    "    h = np.zeros(I.shape[:2])\n",
    "    s = np.zeros(I.shape[:2])\n",
    "    v = cmax * 100\n",
    "    # calculate h, s\n",
    "    for i in range(h.shape[0]):\n",
    "        for j in range(h.shape[1]):\n",
    "            # saturation\n",
    "            if cmax[i, j] > 0:\n",
    "                s[i, j] = diff[i, j] / cmax[i, j] * 100\n",
    "            # Both are zero\n",
    "            if cmax[i, j] == cmin[i, j]:\n",
    "                continue\n",
    "            # r\n",
    "            if max_color[i, j] == 0:\n",
    "                h[i, j] = (60 * ((I[i, j, 1] - I[i, j, 2]) / diff[i, j]) + 360) % 360\n",
    "            # g\n",
    "            if max_color[i, j] == 1:\n",
    "                h[i, j] = (60 * ((I[i, j, 2] - I[i, j, 0]) / diff[i, j]) + 120) % 360\n",
    "            # b\n",
    "            if max_color[i, j] == 2:\n",
    "                h[i, j] = (60 * ((I[i, j, 0] - I[i, j, 1]) / diff[i, j]) + 240) % 360\n",
    "    # Flip hue so that red is in the 180 band instead of 0, 360 band\n",
    "    h  = (h + 180) % 360\n",
    "    \"\"\"\n",
    "    print('h:', h[:5, :5])\n",
    "    print('s:', s[:5, :5])\n",
    "    print('v:', v[:5, :5])\n",
    "    print('h:', h)\n",
    "    print('s:', s)\n",
    "    print('v:', v)\n",
    "    if h.shape[0] > 300:\n",
    "        cv2.imshow('image', h / 2)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.imshow('image', s)\n",
    "        cv2.waitKey(0)\n",
    "        cv2.imshow('image', v)\n",
    "        cv2.waitKey(0)\n",
    "    \"\"\"\n",
    "    return np.stack([h, s, v]).transpose([1,2,0]).astype(np.uint8)\n",
    "\n",
    "\n",
    "def normalize_image(img, source_img=None, axis=None):\n",
    "    if source_img is None:\n",
    "        source_img = img\n",
    "    return (\n",
    "        (\n",
    "            img\n",
    "            # - source_img.mean(axis=axis, keepdims=True)\n",
    "        ) /\n",
    "        np.linalg.norm(source_img)\n",
    "    )\n",
    "\n",
    "\n",
    "def process_filters(img, read_only=False):\n",
    "    if read_only:\n",
    "        img = img.copy()\n",
    "    hsv = rgb_to_hsv(img)\n",
    "    img = np.concatenate((img, hsv), axis=2)\n",
    "    return img\n",
    "\n",
    "\n",
    "def imshow_hsv(I):\n",
    "    cv2_hsv = I.copy()\n",
    "    cv2_hsv[:,:,0] /= 2\n",
    "    cv2_hsv[:,:,1] *= 2.55\n",
    "    cv2_hsv[:,:,2] *= 2.55\n",
    "    cv2_hsv = np.round(cv2_hsv).astype(np.uint8)\n",
    "    #print('viewed h:', cv2_hsv[:5, :5, 0])\n",
    "    #print('viewed s:', cv2_hsv[:5, :5, 1])\n",
    "    #print('viewed v:', cv2_hsv[:5, :5, 2])\n",
    "    #print('viewed hsv:', cv2_hsv, cv2_hsv.shape, cv2_hsv.dtype)\n",
    "    #proper_hsv = cv2.cvtColor(original_I, cv2.COLOR_RGB2HSV)\n",
    "    #print(\"proper hsv:\", proper_hsv, proper_hsv.shape, proper_hsv.dtype)\n",
    "    #print(cv2_hsv.shape)\n",
    "    cv2.imshow('image', cv2.cvtColor(cv2_hsv, cv2.COLOR_HSV2BGR))\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "    \"\"\"cv2.imshow('image', cv2_hsv[:, :, 0])\n",
    "    cv2.waitKey(0)\n",
    "    cv2.imshow('image', cv2_hsv[:, :, 1])\n",
    "    cv2.waitKey(0)\n",
    "    cv2.imshow('image', cv2_hsv[:, :, 2])\n",
    "    cv2.waitKey(0)\"\"\"\n",
    "\n",
    "    \n",
    "def imshow_rgb(I):\n",
    "    cv2.imshow('image', cv2.cvtColor(I, cv2.COLOR_RGB2BGR))\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "\n",
    "def imshow_mpl_rgb(I):\n",
    "    imshow(I)\n",
    "\n",
    "    \n",
    "def imshow_mpl_hsv(I):\n",
    "    cv2_hsv = I.copy().astype(np.float)\n",
    "    cv2_hsv[:,:,0] /= 2\n",
    "    cv2_hsv[:,:,1] *= 2.55\n",
    "    cv2_hsv[:,:,2] *= 2.55\n",
    "    cv2_hsv = np.round(cv2_hsv).astype(np.uint8)\n",
    "    imshow(cv2.cvtColor(cv2_hsv, cv2.COLOR_HSV2RGB))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Filter:\n",
    "    def __init__(self, filepath, thres, sourcepath, factor=SCALE_FACTOR):\n",
    "        self.factor = factor\n",
    "        rgb_source_I = np.asarray(Image.open(os.path.join(sourcepath)))\n",
    "        self.rgb_source_I = rgb_source_I\n",
    "        rgb_source_I = downsample(rgb_source_I, self.factor)\n",
    "        self.source_I = process_filters(rgb_source_I, read_only=True)\n",
    "        rgb_ref_I = np.asarray(Image.open(os.path.join(filepath)))\n",
    "        self.rgb_ref_I = rgb_ref_I\n",
    "        rgb_ref_I = downsample(rgb_ref_I, self.factor)\n",
    "        rgb_ref_I = process_filters(rgb_ref_I, read_only=True)\n",
    "        self.unnorm_rgb_ref_I = rgb_ref_I\n",
    "        print(rgb_ref_I[:rgb_ref_I.shape[0] // 2].mean(axis=0).mean(axis=0))\n",
    "        print(rgb_ref_I[rgb_ref_I.shape[0] // 2:].mean(axis=0).mean(axis=0))\n",
    "        self.ref_I = normalize_image(rgb_ref_I)\n",
    "        self.ref_vec = self.ref_I.flatten()\n",
    "        print(self.ref_I.shape, self.source_I.mean())\n",
    "        self.ref_rows, self.ref_cols = self.ref_I.shape[:2]\n",
    "        self.thres = thres\n",
    "        \n",
    "        # means for filtering\n",
    "        self.top_means = self.unnorm_rgb_ref_I[:self.ref_rows//2].mean(axis=0).mean(axis=0)\n",
    "        self.bottom_means = self.unnorm_rgb_ref_I[self.ref_rows//2:].mean(axis=0).mean(axis=0)\n",
    "        # rgb hsv\n",
    "        self.top_tols = [\n",
    "            [-20, 1000],\n",
    "            [-1000, 10],\n",
    "            [-1000, 10],\n",
    "            [-15, 15],\n",
    "            [-15, 1000],\n",
    "            [-15, 1000],\n",
    "        ]\n",
    "        self.bottom_tols = [\n",
    "            [-1000, 1000],\n",
    "            [-1000, 1000],\n",
    "            [-1000, 1000],\n",
    "            [-1000, 1000],\n",
    "            [-1000, 1000],\n",
    "            [-1000, 20],\n",
    "        ]\n",
    "\n",
    "\n",
    "    def test_handcrafted_filter(self, sub_mat):\n",
    "        img_top_means = sub_mat[:sub_mat.shape[0]//2].mean(axis=0).mean(axis=0)\n",
    "        img_bottom_means = sub_mat[sub_mat.shape[0]//2:].mean(axis=0).mean(axis=0)\n",
    "        \n",
    "        for i, tol in enumerate(self.top_tols):\n",
    "            if img_top_means[i] < self.top_means[i] + tol[0] or img_top_means[i] > self.top_means[i] + tol[1]:\n",
    "                return False\n",
    "        for i, tol in enumerate(self.top_tols):\n",
    "            if img_bottom_means[i] < self.bottom_means[i] + tol[0] or img_bottom_means[i] > self.bottom_means[i] + tol[1]:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "\n",
    "    def get_detections(self, I):\n",
    "        # Assume I is already downsampled and processed\n",
    "        # run convolution\n",
    "        n_rows, n_cols = I.shape[:2]\n",
    "        bboxes = []\n",
    "        confs = []\n",
    "        print(I.mean())\n",
    "        ind = 0\n",
    "        for row in range(0, int(n_rows * 0.7) - self.ref_rows, max(self.ref_rows // 10, 1)):\n",
    "            for col in range(0, n_cols - self.ref_cols, max(self.ref_cols // 10, 1)):\n",
    "                ind += 1\n",
    "                if ind % 1 != 0:\n",
    "                    continue\n",
    "                sub_mat = I[row:row+self.ref_rows,\n",
    "                            col:col+self.ref_cols]\n",
    "                if not self.test_handcrafted_filter(sub_mat):\n",
    "                    continue\n",
    "                # sub_mat = process_filters(sub_mat)\n",
    "                sub_vec = normalize_image(sub_mat.flatten())\n",
    "                conf = np.dot(sub_vec, self.ref_vec)\n",
    "                if row == 197 // 2 and col == 463 // 2:\n",
    "                    print(\"YOLO:\", conf)\n",
    "                confs.append(conf)\n",
    "                if conf > self.thres:\n",
    "                    print('conf', conf, 'means', sub_mat[:sub_mat.shape[0]//2].mean(axis=0).mean(axis=0),\n",
    "                          'coords:', col, row)\n",
    "                    ind -= 1\n",
    "                    bboxes.append([\n",
    "                        row * self.factor, col * self.factor,\n",
    "                        (row+self.ref_rows) * self.factor,\n",
    "                        (col+self.ref_cols) * self.factor,\n",
    "                        conf\n",
    "                    ])\n",
    "        \n",
    "        print(sorted(confs)[-10:])\n",
    "        print('num boxes:', len(bboxes))\n",
    "        return bboxes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_red_light_mf(I, det_filters, factor=SCALE_FACTOR):\n",
    "    '''\n",
    "    This function takes a numpy array <I> and returns a list <output>.\n",
    "    The length of <output> is the number of bounding boxes predicted for <I>. \n",
    "    Each entry of <output> is a list <[row_TL,col_TL,row_BR,col_BR,score]>. \n",
    "    The first four entries are four integers specifying a bounding box \n",
    "    (the row and column index of the top left corner and the row and column \n",
    "    index of the bottom right corner).\n",
    "    <score> is a confidence score ranging from 0 to 1. \n",
    "\n",
    "    Note that PIL loads images in RGB order, so:\n",
    "    I[:,:,0] is the red channel\n",
    "    I[:,:,1] is the green channel\n",
    "    I[:,:,2] is the blue channel\n",
    "    '''\n",
    "\n",
    "    '''\n",
    "    BEGIN YOUR CODE\n",
    "    '''\n",
    "\n",
    "    bboxes = [] # This should be a list of lists, each of length 4. See format example below. \n",
    "    \n",
    "    '''\n",
    "    BEGIN YOUR CODE\n",
    "    '''\n",
    "    \n",
    "    '''\n",
    "    As an example, here's code that generates between 1 and 5 random boxes\n",
    "    of fixed size and returns the results in the proper format.\n",
    "    '''\n",
    "    \n",
    "    (n_rows,n_cols,n_channels) = np.shape(I)\n",
    "    \n",
    "    original_I = I.copy()\n",
    "    # downsample\n",
    "    I = downsample(I, factor)\n",
    "    I = process_filters(I)\n",
    "\n",
    "    bboxes = []\n",
    "    for det_filter in det_filters:\n",
    "        # Similar to predict_boxes(compute_convolution(I, T))\n",
    "        bboxes.extend(det_filter.get_detections(I))\n",
    "\n",
    "    print('# bboxes before nms:', len(bboxes))\n",
    "    bboxes = run_nms(bboxes)\n",
    "    print('# bboxes after nms:', len(bboxes))\n",
    "    bboxes = sorted(bboxes, key=lambda x: x[4])\n",
    "    print(\"Best bboxes:\\n\", bboxes[-10:])\n",
    "\n",
    "    if len(bboxes) == 0:\n",
    "        return bboxes\n",
    "\n",
    "    for bbox in bboxes[-10:]:\n",
    "        original_I = draw_rectangle(original_I, bbox)\n",
    "        original_I = np.asarray(original_I)\n",
    "\n",
    "    imshow_rgb(original_I)\n",
    "\n",
    "    output = bboxes\n",
    "    '''\n",
    "    END YOUR CODE\n",
    "    '''\n",
    "    for i in range(len(output)):\n",
    "        assert len(output[i]) == 5\n",
    "        assert (output[i][4] >= 0.0) and (output[i][4] <= 1.0)\n",
    "\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_det_filters(filters_path, filters_info_filename):\n",
    "    # get detection filters\n",
    "    det_filters = []\n",
    "    with open(os.path.join(filters_path, filters_info_filename)) as csvfile:\n",
    "        reader = csv.reader(csvfile)\n",
    "        next(reader)\n",
    "        # next(reader)\n",
    "        # next(reader)\n",
    "        for row in reader:\n",
    "            det_filters.append(\n",
    "                Filter(\n",
    "                    os.path.join(filters_path, row[0]),\n",
    "                    float(row[1]),\n",
    "                    os.path.join(filters_path, row[2]),\n",
    "                ))\n",
    "    return det_filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[178.16666667  60.26190476  75.0952381  174.30952381  73.73809524\n",
      "  69.38095238]\n",
      "(12, 7, 6) 45.89083333333333\n",
      "[ 87.57142857  46.21428571  44.21428571 182.07142857  48.0952381\n",
      "  33.88095238]\n",
      "(12, 7, 6) 71.91898654513889\n",
      "[174.04 121.28  99.6  194.88  45.12  67.88]\n",
      "(11, 5, 6) 69.98797092013889\n",
      "[ 97.58333333  32.02777778  45.83333333 148.91666667  58.66666667\n",
      "  38.58333333]\n",
      "(12, 6, 6) 57.430201822916665\n"
     ]
    }
   ],
   "source": [
    "# Note that you are not allowed to use test data for training.\n",
    "# set the path to the downloaded data:\n",
    "data_path = '../data/RedLights2011_Medium'\n",
    "\n",
    "# set the path to load the filters csv:\n",
    "filters_path = '../data/filters'\n",
    "filters_info_filename = 'thresholds.csv'\n",
    "\n",
    "# load splits: \n",
    "split_path = '../data/hw02_splits'\n",
    "file_names_train = np.load(os.path.join(split_path,'file_names_train.npy'))\n",
    "file_names_test = np.load(os.path.join(split_path,'file_names_test.npy'))\n",
    "\n",
    "# set a path for saving predictions:\n",
    "preds_path = '../data/hw02_preds'\n",
    "os.makedirs(preds_path, exist_ok=True) # create directory if needed\n",
    "\n",
    "# Set this parameter to True when you're done with algorithm development:\n",
    "done_tweaking = False\n",
    "\n",
    "# get detection filters\n",
    "det_filters = get_det_filters(filters_path, filters_info_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "# det_filters = [det_filters[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_ind = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "imshow_mpl_rgb(downsample(det_filters[filter_ind].rgb_ref_I, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[111 116 142 156 167 167 148 134 104 107]\n",
      " [109 126 164 183 185 186 167 132 102 107]\n",
      " [126 137 190 231 243 239 201 135 114 121]\n",
      " [130 153 228 255 255 255 253 161 111 120]\n",
      " [131 134 230 255 254 253 255 160 106 116]\n",
      " [126 131 234 255 251 255 255 157 101 112]\n",
      " [120 122 194 251 255 255 220 140 102 111]\n",
      " [105 118 132 160 169 175 132 112  96 106]\n",
      " [107 107 120 118 119 119 125 113 100  97]\n",
      " [ 93  92  93  96 104 105 101  92  87  86]\n",
      " [ 83  83  80  91 106 105  88  81  72  82]\n",
      " [ 72  76  69  84  96  97  76  69  57  75]\n",
      " [ 70  70  60  61  55  60  54  53  52  73]\n",
      " [ 74  70  55  44  25  31  41  51  52  75]\n",
      " [ 70  64  47  39  24  27  38  49  49  70]\n",
      " [ 67  55  39  37  34  38  39  47  56  72]\n",
      " [ 66  54  37  34  42  46  35  48  57  74]\n",
      " [ 61  57  43  57  69  70  47  45  56  72]\n",
      " [ 64  61  41  47  49  55  45  47  50  67]\n",
      " [ 67  54  40  41  38  33  30  45  52  67]\n",
      " [ 60  71  79  44  27  38  53  68  50  63]\n",
      " [ 62  54  70  48  44  44  47  58  55  67]]\n",
      "(22, 10, 3)\n"
     ]
    }
   ],
   "source": [
    "ref = det_filters[filter_ind].rgb_ref_I\n",
    "print(ref[:,:,0])\n",
    "print(ref.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "det_filters[filter_ind].ref_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_coords = [\n",
    "    [],\n",
    "    [],\n",
    "    [176,323],\n",
    "    [],\n",
    "    [197, 463]\n",
    "]\n",
    "gt = det_filters[filter_ind].rgb_source_I[gt_coords[filter_ind][0]:gt_coords[filter_ind][0]+(det_filters[filter_ind].ref_rows * SCALE_FACTOR),\n",
    "                                          gt_coords[filter_ind][1]:gt_coords[filter_ind][1]+(det_filters[filter_ind].ref_cols * SCALE_FACTOR),:]\n",
    "# gt[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([144.57272727,  89.68181818,  81.72727273]),\n",
       " array([177.74545455,  45.47272727,  56.36363636]))"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gt[:11].mean(axis=0).mean(axis=0), rgb_to_hsv(gt)[:11].mean(axis=0).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([152.1875,  82.2375,  70.575 ]), array([183.5875,  56.2625,  59.3125]))"
      ]
     },
     "execution_count": 206,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nice_gt = det_filters[filter_ind].rgb_source_I[gt_coords[filter_ind][0]:gt_coords[filter_ind][0]+(det_filters[-1].ref_rows * SCALE_FACTOR),\n",
    "                                          gt_coords[filter_ind][1]:gt_coords[filter_ind][1]+(det_filters[-1].ref_cols * SCALE_FACTOR),:]\n",
    "nice_gt[:10, :8].mean(axis=0).mean(axis=0), rgb_to_hsv(nice_gt[:10, :8]).mean(axis=0).mean(axis=0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 95, 108, 147, 187, 189, 159, 114,  87],\n",
       "       [102, 132, 185, 210, 206, 178, 146, 108],\n",
       "       [120, 171, 230, 243, 251, 221, 161, 127],\n",
       "       [130, 198, 255, 255, 255, 255, 188, 133],\n",
       "       [127, 178, 255, 255, 248, 255, 177, 118],\n",
       "       [110, 144, 219, 255, 255, 225, 150, 109],\n",
       "       [ 91, 118, 153, 188, 202, 163, 134, 100],\n",
       "       [ 87, 102, 129, 147, 157, 146, 127, 100],\n",
       "       [ 85,  94,  93, 108, 114, 102,  94,  90],\n",
       "       [ 81,  83,  74,  84,  91,  73,  72,  67],\n",
       "       [ 72,  74,  67,  81,  89,  64,  62,  55],\n",
       "       [ 64,  65,  59,  67,  67,  58,  51,  53],\n",
       "       [ 66,  63,  53,  53,  43,  47,  42,  52],\n",
       "       [ 70,  61,  43,  41,  33,  33,  42,  52],\n",
       "       [ 67,  56,  35,  34,  37,  35,  48,  55],\n",
       "       [ 66,  60,  45,  51,  64,  52,  56,  60],\n",
       "       [ 65,  58,  40,  47,  45,  41,  37,  49],\n",
       "       [ 66,  54,  47,  33,  36,  31,  45,  45],\n",
       "       [ 62,  67,  78,  44,  36,  44,  73,  52],\n",
       "       [ 63,  61,  67,  49,  44,  55,  54,  56]], dtype=uint8)"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nice_gt[:20,:8,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "imshow_mpl_rgb(downsample(gt, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[176, 175, 178, 181, 182],\n",
       "       [182, 234, 240, 201, 183],\n",
       "       [184, 240, 243, 208, 180],\n",
       "       [182, 185, 186, 180, 164],\n",
       "       [174, 163, 168, 190, 205],\n",
       "       [180, 180, 180, 207, 229],\n",
       "       [180, 180, 192, 149, 120],\n",
       "       [165, 180, 180, 202, 180],\n",
       "       [ 37,  42,  32,  37,  89],\n",
       "       [ 37,  42,  41,  37,  25],\n",
       "       [ 37,  37,  32,  37,  25]], dtype=uint8)"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "downsample(rgb_to_hsv(gt), 2)[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "imshow_mpl_hsv(downsample(rgb_to_hsv(gt), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[176, 175, 178, 181, 182],\n",
       "       [182, 234, 240, 201, 183],\n",
       "       [184, 240, 243, 208, 180],\n",
       "       [182, 185, 186, 180, 164],\n",
       "       [174, 163, 168, 190, 205],\n",
       "       [180, 180, 180, 207, 229],\n",
       "       [180, 180, 192, 149, 120],\n",
       "       [165, 180, 180, 202, 180],\n",
       "       [ 37,  42,  32,  37,  89],\n",
       "       [ 37,  42,  41,  37,  25],\n",
       "       [ 37,  37,  32,  37,  25]], dtype=uint8)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "downsample(rgb_to_hsv(gt), 2).copy()[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "coords = [262, 168]\n",
    "fp = det_filters[-1].rgb_source_I[coords[0]:coords[0]+24,coords[1]:coords[1]+12,:]\n",
    "# fp[:,:,0]\n",
    "\n",
    "fp_coords = [\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    "    [],\n",
    "    [262, 168] # [234, 624] \n",
    "]\n",
    "gt = det_filters[filter_ind].rgb_source_I[gt_coords[filter_ind][0]:gt_coords[filter_ind][0]+(det_filters[filter_ind].ref_rows * SCALE_FACTOR),\n",
    "                                          gt_coords[filter_ind][1]:gt_coords[filter_ind][1]+(det_filters[filter_ind].ref_cols * SCALE_FACTOR),:]\n",
    "# gt[:,:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([73.86111111, 59.09722222, 51.75      ])"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp[:12].mean(axis=0).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.82638889, 8.82638889, 7.82638889])"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fp[:12].mean(axis=0).mean(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8585721842391871 1.0 0.946382409546846\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    np.sum(normalize_image(ref) * normalize_image(gt)),\n",
    "    np.sum(normalize_image(gt) * normalize_image(gt)),\n",
    "    #np.sum(normalize_image(ref) * normalize_image(fp)),\n",
    "    np.sum(normalize_image(rgb_to_hsv(ref)) * normalize_image(rgb_to_hsv(gt))),\n",
    "    #np.sum(normalize_image(rgb_to_hsv(ref)) * normalize_image(rgb_to_hsv(fp))),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8388298853724335 0.9460359908007037\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    np.sum(normalize_image(downsample(ref, 2)) * normalize_image(downsample(gt, 2))),\n",
    "    #np.sum(normalize_image(downsample(ref, 2)) * normalize_image(downsample(fp, 2))),\n",
    "    np.sum(normalize_image(rgb_to_hsv(downsample(ref, 2))) * normalize_image(rgb_to_hsv(downsample(gt, 2)))),\n",
    "    #np.sum(normalize_image(rgb_to_hsv(downsample(ref, 2))) * normalize_image(rgb_to_hsv(downsample(fp, 2)))),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9943785329164838 0.2997970813785265 0.948233244120727 0.8134053044443802\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    np.sum(normalize_image(downsample(ref, 2)) * normalize_image(downsample(gt, 2))),\n",
    "    np.sum(normalize_image(downsample(ref, 2)) * normalize_image(downsample(fp, 2))),\n",
    "    np.sum(normalize_image(rgb_to_hsv(downsample(ref, 2))) * normalize_image(rgb_to_hsv(downsample(gt, 2)))),\n",
    "    np.sum(normalize_image(rgb_to_hsv(downsample(ref, 2))) * normalize_image(rgb_to_hsv(downsample(fp, 2)))),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[178.16666667  60.26190476  75.0952381  174.30952381  73.73809524\n",
      "  69.38095238]\n",
      "[ 76.26190476   7.78571429  14.78571429 173.19047619  86.0952381\n",
      "  29.38095238]\n",
      "(12, 7, 6) 45.89083333333333\n",
      "[138.875   72.4375  70.4375 182.125   54.5625  53.9375]\n",
      "[ 39.15  30.65  28.3  202.4   25.35  14.75]\n",
      "(9, 4, 6) 71.91898654513889\n",
      "[174.04 121.28  99.6  194.88  45.12  67.88]\n",
      "[ 65.9         60.53333333  63.06666667 101.5         14.1\n",
      "  26.73333333]\n",
      "(11, 5, 6) 69.98797092013889\n",
      "[140.55555556  53.88888889  75.         165.55555556  62.11111111\n",
      "  54.44444444]\n",
      "[33.41666667 30.66666667 36.08333333 77.91666667 21.75       14.58333333]\n",
      "(7, 3, 6) 90.2045724826389\n",
      "[119.38690476  72.29166667  49.44047619 183.35119048  54.24404762\n",
      "  46.5297619 ]\n",
      "[ 33.17777778  31.95555556  32.77222222 102.24444444  11.53888889\n",
      "  13.20555556]\n",
      "(29, 12, 6) 74.79226996527778\n",
      "[ 97.58333333  32.02777778  45.83333333 148.91666667  58.66666667\n",
      "  38.58333333]\n",
      "[18.36111111 22.44444444 26.19444444 50.11111111 31.25       10.08333333]\n",
      "(12, 6, 6) 57.430201822916665\n"
     ]
    }
   ],
   "source": [
    "det_filters = get_det_filters(filters_path, filters_info_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file name: RL-011.jpg\n",
      "74.79226996527778\n",
      "[]\n",
      "num boxes: 0\n",
      "74.79226996527778\n",
      "[]\n",
      "num boxes: 0\n",
      "74.79226996527778\n",
      "[]\n",
      "num boxes: 0\n",
      "74.79226996527778\n",
      "[]\n",
      "num boxes: 0\n",
      "74.79226996527778\n",
      "conf 0.9140703267758535 means [117.54761905  73.70238095  48.2202381  183.93452381  50.19047619\n",
      "  45.7202381 ] coords: 81 30\n",
      "conf 0.9477658494491499 means [118.94047619  73.4702381   48.26190476 183.63690476  52.04166667\n",
      "  46.26190476] coords: 82 30\n",
      "conf 0.9547258279221053 means [119.01190476  73.51785714  48.16666667 184.08928571  52.21428571\n",
      "  46.28571429] coords: 83 30\n",
      "conf 0.926289877392634 means [118.10119048  73.42857143  48.42261905 181.7202381   51.5297619\n",
      "  45.97619048] coords: 84 30\n",
      "conf 0.958462449768015 means [121.31547619  73.07142857  49.63690476 181.69642857  54.42261905\n",
      "  47.23214286] coords: 176 34\n",
      "conf 0.9368988792632226 means [121.57738095  75.05357143  51.73214286 171.39880952  53.07738095\n",
      "  47.64285714] coords: 177 34\n",
      "conf 0.9400108773444051 means [118.61904762  72.85714286  48.89285714 181.73809524  51.13095238\n",
      "  46.16071429] coords: 175 36\n",
      "conf 0.961412398569937 means [118.86904762  72.67261905  48.75       181.07142857  52.02380952\n",
      "  46.27380952] coords: 176 36\n",
      "conf 0.9333019242069877 means [118.88095238  74.17261905  50.39285714 172.30357143  50.66666667\n",
      "  46.52380952] coords: 177 36\n",
      "[0.895230520369194, 0.9140703267758535, 0.926289877392634, 0.9333019242069877, 0.9368988792632226, 0.9400108773444051, 0.9477658494491499, 0.9547258279221053, 0.958462449768015, 0.961412398569937]\n",
      "num boxes: 9\n",
      "74.79226996527778\n",
      "[]\n",
      "num boxes: 0\n",
      "# bboxes before nms: 9\n",
      "# bboxes after nms: 2\n",
      "Best bboxes:\n",
      " [[60, 166, 118, 190, 0.9547258279221053], [72, 352, 130, 376, 0.961412398569937]]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "Make predictions on the training set.\n",
    "'''\n",
    "preds_train = {}\n",
    "for i in range(len(file_names_train)):\n",
    "    file_names_train[i] = 'RL-011.jpg'\n",
    "    print('file name:', file_names_train[i])\n",
    "    # read image using PIL:\n",
    "    I = Image.open(os.path.join(data_path,file_names_train[i]))\n",
    "\n",
    "    # convert to numpy array:\n",
    "    I = np.asarray(I)\n",
    "\n",
    "    preds_train[file_names_train[i]] = detect_red_light_mf(I, det_filters)\n",
    "    break\n",
    "\n",
    "# save preds (overwrites any previous predictions!)\n",
    "with open(os.path.join(preds_path,'preds_train.json'),'w') as f:\n",
    "    json.dump(preds_train,f)\n",
    "\n",
    "if done_tweaking:\n",
    "    '''\n",
    "    Make predictions on the test set. \n",
    "    '''\n",
    "    preds_test = {}\n",
    "    for i in range(len(file_names_test)):\n",
    "\n",
    "        # read image using PIL:\n",
    "        I = Image.open(os.path.join(data_path,file_names_test[i]))\n",
    "\n",
    "        # convert to numpy array:\n",
    "        I = np.asarray(I)\n",
    "\n",
    "        preds_test[file_names_test[i]] = detect_red_light_mf(I)\n",
    "\n",
    "    # save preds (overwrites any previous predictions!)\n",
    "    with open(os.path.join(preds_path,'preds_test.json'),'w') as f:\n",
    "        json.dump(preds_test,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "import multiprocessing\n",
    "\n",
    "def worker(procnum, return_dict):\n",
    "    '''worker function'''\n",
    "    print(str(procnum) + ' represent!')\n",
    "    return_dict[procnum] = procnum\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    manager = multiprocessing.Manager()\n",
    "    return_dict = manager.dict()\n",
    "    jobs = []\n",
    "    for i in range(5):\n",
    "        p = multiprocessing.Process(target=worker, args=(i,return_dict))\n",
    "        jobs.append(p)\n",
    "        p.start()\n",
    "\n",
    "    for proc in jobs:\n",
    "        proc.join()\n",
    "    print(return_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_dict.values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
